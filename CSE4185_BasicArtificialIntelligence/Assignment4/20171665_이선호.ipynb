{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b9f4f2b191a44c57b6ffcbd5531a026b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_14bea2ded3d94d6384b90ff94f873858",
              "IPY_MODEL_5767f3a3d1134c9bb54598efe96c27a5",
              "IPY_MODEL_cd1b31b6334242cd91d77449a849f63e"
            ],
            "layout": "IPY_MODEL_c23649b02ea645dab41507d82aa52076"
          }
        },
        "14bea2ded3d94d6384b90ff94f873858": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56822029b6ae49a281b416da13e809b8",
            "placeholder": "​",
            "style": "IPY_MODEL_d9a19f56e2d14e009b8964ef83b3f81e",
            "value": "100%"
          }
        },
        "5767f3a3d1134c9bb54598efe96c27a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9aad1595eddf4db8bba99ff7b1d3a3a4",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_25152b8e617b4dd99ba466afc3bf2fde",
            "value": 170498071
          }
        },
        "cd1b31b6334242cd91d77449a849f63e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9538599fe6c4837a60e4f1b3b0a241e",
            "placeholder": "​",
            "style": "IPY_MODEL_3ba8e98ccb0246f9ad0075ce59f2e26a",
            "value": " 170498071/170498071 [00:03&lt;00:00, 52799040.77it/s]"
          }
        },
        "c23649b02ea645dab41507d82aa52076": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56822029b6ae49a281b416da13e809b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9a19f56e2d14e009b8964ef83b3f81e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9aad1595eddf4db8bba99ff7b1d3a3a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25152b8e617b4dd99ba466afc3bf2fde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b9538599fe6c4837a60e4f1b3b0a241e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ba8e98ccb0246f9ad0075ce59f2e26a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZJFbNjqKjjht"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from typing import List"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print('device_check:',device) # GPU 사용이 가능하면 cuda 출력 / 불가능하면 cpu 출력"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggMHzU2KtFu3",
        "outputId": "ea05ee59-59d5-42e9-b993-dd86461a6ef8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device_check: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section I. PyTorch 이용하여 MLP 만들기"
      ],
      "metadata": {
        "id": "dVgFeSPP72P2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# One-Layer Perceptron 예제\n",
        "## PyTorch에서는 torch.nn.Linear를 이용하여 간단하게 perceptron을 구현할 수 있다.\n",
        "## torch.nn.Linear의 paramters\n",
        "* in_features: input data (2차원 행렬)에서 column의 개수\n",
        "* out_features: output data (2차원 행렬)에서 column의 개수\n",
        "\n",
        "## torch.nn.Linear의 input\n",
        "* input은 [batch_size, row, column] 사이즈를 가진 행렬 형태여야 한다. (row X column 행렬)\n",
        "* batch_size란 row X column 행렬이 독립적으로 몇 개 존재하는지 정도로 이해하도록 한다.\n",
        "* batch_size에 대해 더 궁금한 점은 검색해서 찾아보기\n",
        "\n",
        "## GPU 사용\n",
        "#### model = model.to(device) 로 선언한 후\n",
        "#### model의 input data 역시 input_data = input_data.to(device)로 선언해주어야 한다."
      ],
      "metadata": {
        "id": "6w0CR4zGpm_B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# nn.Linear 예제\n",
        "\n",
        "one_layer = nn.Linear(3,8).to(device)\n",
        "input_data = torch.randn(5,12,3).to(device) # 12 X 3 행렬이 독립적으로 5개 있음을 의미함\n",
        "out = one_layer(input_data)\n",
        "print(f'output 사이즈: {out.size()}') # [5, 12, 8]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8t2dPf0epSLV",
        "outputId": "74a332d9-539b-45d2-e056-1f8011b0e4d2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output 사이즈: torch.Size([5, 12, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Two-Layer Perceptron 예제\n",
        "## nn.Sequential은 두 개의 레이어가 순차적으로 실행되게 하는 함수이다.\n",
        "### 아래 예제에서 input_data는 처음 perceptron nn.Linear(3,8)을 통과한 후 [5,12,8]의 사이즈를 가지게 된다.\n",
        "### 바로 다음 두번째 perceptron nn.Linear(8,16)을 통과한 후에는 [5,12,16]의 사이즈를 가지게 된다."
      ],
      "metadata": {
        "id": "_Di8VgkoznrO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# nn.Sequential 예제\n",
        "\n",
        "two_layer = nn.Sequential(nn.Linear(3,8),\n",
        "                          nn.Linear(8,16)).to(device)\n",
        "input_data = torch.randn(5,12,3).to(device) # 12 X 3 행렬이 독립적으로 5개 있음을 의미함\n",
        "out = two_layer(input_data)\n",
        "print(f'output 사이즈: {out.size()}') # [5, 12, 16]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVKqcK6oznKA",
        "outputId": "479e4536-61ba-42d1-d715-60ab18f62aef"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output 사이즈: torch.Size([5, 12, 16])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Activation Function\n",
        "### activation function은 neural network의 layer를 통과한 후 output data 변형을 주는 함수이다.\n",
        "### 일반적으로 neural network의 layer는 linear이기 때문에 activation function로는 non-linear 함수를 많이 사용한다.\n",
        "### 이를 통해 neural network가 단일 linear function으로 귀결되는 것을 방지하고, 결과적으로 성능향상을 이끌 수 있다.\n",
        "\n",
        "### 대표적인 activation function (nn 모듈을 이용하여 사용가능)\n",
        "* Sigmoid (시그모이드)\n",
        "* ReLU (렐루)\n",
        "* tanh (하이퍼볼릭 탄제트)\n",
        "#### 각 함수의 수식은 각자 검색하기"
      ],
      "metadata": {
        "id": "T8GRA24a3HBN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# activation function 예제\n",
        "sigmoid = nn.Sigmoid()\n",
        "relu = nn.ReLU()\n",
        "tanh = nn.Tanh()\n",
        "\n",
        "torch.random.manual_seed(100) # 랜덤시드 고정\n",
        "input_data = torch.randn(1,5,3)\n",
        "\n",
        "print('인풋데이터 확인')\n",
        "print(input_data)\n",
        "\n",
        "sigmoid_output = sigmoid(input_data)\n",
        "relu_output = relu(input_data)\n",
        "tanh_output = tanh(input_data)\n",
        "\n",
        "print('시그모이드 아웃풋')\n",
        "print(sigmoid_output)\n",
        "\n",
        "print('렐루 아웃풋')\n",
        "print(relu_output)\n",
        "\n",
        "print('하이퍼볼릭 탄젠트 아웃풋')\n",
        "print(tanh_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8m3OmtGY3HRz",
        "outputId": "cc6bc9bc-9e07-40ea-c3d6-ad8796ba11eb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "인풋데이터 확인\n",
            "tensor([[[ 0.3607, -0.2859, -0.3938],\n",
            "         [ 0.2429, -1.3833, -2.3134],\n",
            "         [-0.3172, -0.8660,  1.7482],\n",
            "         [-0.2759, -0.9755,  0.4790],\n",
            "         [-2.3652, -0.8047,  0.6587]]])\n",
            "시그모이드 아웃풋\n",
            "tensor([[[0.5892, 0.4290, 0.4028],\n",
            "         [0.5604, 0.2005, 0.0900],\n",
            "         [0.4214, 0.2961, 0.8517],\n",
            "         [0.4315, 0.2738, 0.6175],\n",
            "         [0.0859, 0.3090, 0.6590]]])\n",
            "렐루 아웃풋\n",
            "tensor([[[0.3607, 0.0000, 0.0000],\n",
            "         [0.2429, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 1.7482],\n",
            "         [0.0000, 0.0000, 0.4790],\n",
            "         [0.0000, 0.0000, 0.6587]]])\n",
            "하이퍼볼릭 탄젠트 아웃풋\n",
            "tensor([[[ 0.3458, -0.2784, -0.3746],\n",
            "         [ 0.2383, -0.8817, -0.9806],\n",
            "         [-0.3070, -0.6994,  0.9412],\n",
            "         [-0.2691, -0.7511,  0.4454],\n",
            "         [-0.9825, -0.6666,  0.5775]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# nn.Linear + nn.Sequential + activation function 종합 예제\n",
        "my_model = nn.Sequential(nn.Linear(3,8),\n",
        "                         nn.Sigmoid(),\n",
        "                         nn.Linear(8,16),\n",
        "                         nn.ReLU()).to(device)\n",
        "input_data = torch.randn(5,12,3).to(device)\n",
        "out = my_model(input_data)\n",
        "print(f'output 사이즈: {out.size()}') # [5, 12, 16]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hOb4jne8I5d",
        "outputId": "d96efe2a-82d3-42c9-becf-2d883378eb58"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output 사이즈: torch.Size([5, 12, 16])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 문제1\n",
        "## nn.Linear와 nn.Sequential을 사용하여 Five-Layer Perceptron을 구현하시오. (1점)\n",
        "### 조건\n",
        "* input data 행렬의 row는 12, column은 3이다.\n",
        "* output 행렬의 column은 7이다.\n",
        "* 각 중간 layer의 out_features는 다음 순서를 따른다: [12,14,15,10,7]\n",
        "* activation function은 추가하지 않는다.\n",
        "* five_layer 모델은 GPU에서 실행되게 선언해야 한다."
      ],
      "metadata": {
        "id": "n8sI-sQC0mJC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "five_layer = None\n",
        "######################## TODO ########################\n",
        "five_layer = nn.Sequential(nn.Linear(3, 12), \n",
        "                           nn.Linear(12, 14), \n",
        "                           nn.Linear(14, 15), \n",
        "                           nn.Linear(15, 10), \n",
        "                           nn.Linear(10, 7)).to(device)\n",
        "######################################################\n",
        "input_data = torch.randn(5,12,3).to(device)\n",
        "out = five_layer(input_data)\n",
        "print(f'output 사이즈: {out.size()}') # [5, 12, 7]이 출력되어야 한다."
      ],
      "metadata": {
        "id": "5N0rbCni0LWT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35fcc004-f407-4b2c-ce0e-8626b20b26c0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output 사이즈: torch.Size([5, 12, 7])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 문제2\n",
        "## nn.Linear, nn.Sequential, activation function을 사용하여 Ten-Layer Perceptron을 구현하시오. (1점)\n",
        "\n",
        "### 조건\n",
        "* activation은 Sigmoid, ReLU, tanh 중 하나를 사용한다.\n",
        "* input data 행렬의 row는 12, column은 3이다.\n",
        "* output 행렬의 column은 아래 조건을 참고하여 알맞게 나오도록 한다.\n",
        "* 각 중간 layer의 out_features는 초항이 5, 공차가 2인 등차수열을 따른다. (즉, [5,7,9,...])\n",
        "* ten_layer 모델은 GPU에서 실행되게 선언해야 한다."
      ],
      "metadata": {
        "id": "a4qRlNaqKIsM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ten_layer = None\n",
        "######################## TODO ########################\n",
        "ten_layer = nn.Sequential(nn.Linear(3, 5), nn.ReLU(),\n",
        "                          nn.Linear(5, 7), nn.ReLU(),\n",
        "                          nn.Linear(7, 9), nn.ReLU(),\n",
        "                          nn.Linear(9, 11), nn.ReLU(),\n",
        "                          nn.Linear(11, 13), nn.ReLU(),\n",
        "                          nn.Linear(13, 15), nn.ReLU(),\n",
        "                          nn.Linear(15, 17), nn.ReLU(),\n",
        "                          nn.Linear(17, 19), nn.ReLU(),\n",
        "                          nn.Linear(19, 21), nn.ReLU(),\n",
        "                          nn.Linear(21, 23), nn.ReLU()\n",
        "                          ).to(device)\n",
        "######################################################\n",
        "input_data = torch.randn(5,12,3).to(device)\n",
        "out = ten_layer(input_data)\n",
        "print(f'output 사이즈: {out.size()}') # 위 조건에 알맞은 사이즈가 출력되어야 한다."
      ],
      "metadata": {
        "id": "4RFDC0nqKIUn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58e04fd3-5665-4403-97c9-8dcae7487722"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output 사이즈: torch.Size([5, 12, 23])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# nn.Module 클래스 사용\n",
        "### PyTorch의 장점은 nn.Moudule 클래스를 상속 받아서 사용자가 원하는 neural network를 구성할 수 있다는 점이다.\n",
        "\n",
        "### class 함수 설명\n",
        "* \\_\\_init\\_\\_: 클래스의 인스턴스를 생성할 때 가장 먼저 수행되는 부분. neural network에서 사용할 layer 또는 activation function 등을 정의한다.\n",
        "* forward: 실제로 neural network의 작동을 제어하는 함수. input data를 받은 후 neural network의 각 layer별 실행 순서를 정하고, 최종 output을 return한다."
      ],
      "metadata": {
        "id": "jzIiF9VudYEP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# nn.Module 클래스 예시\n",
        "\n",
        "class MyMLP(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(MyMLP, self).__init__()\n",
        "    layers = [nn.Linear(3,8),\n",
        "              nn.Sigmoid(),\n",
        "              nn.Linear(8,20),\n",
        "              nn.ReLU()]\n",
        "    self.mlp = nn.Sequential(*layers) # 이러한 방식으로도 정의할 수 있다.\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.mlp(x)\n",
        "    return x\n",
        "\n",
        "my_model = MyMLP().to(device)\n",
        "input_data = torch.randn(5,12,3).to(device)\n",
        "out = my_model(input_data)\n",
        "print(f'output 사이즈: {out.size()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ynaMgPGaLfT",
        "outputId": "9cacee05-c032-4b70-ce02-35bf7f2df1e1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output 사이즈: torch.Size([5, 12, 20])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 문제3\n",
        "## 아래 조건에 맞게 nn.Module을 상속받는 클래스를 정의하시오. (3점)\n",
        "\n",
        "### 조건\n",
        "* MLP (Multi-Layer Perceptron)의 layer는 nn.Linear만 사용한다.\n",
        "* \\_\\_init\\_\\_ 함수의 parameter 중 num_layers는 MLP의 layer의 개수를 의미한다.\n",
        "* \\_\\_init\\_\\_ 함수의 parameter 중 out_feat_list는 순서대로 MLP의 layer들의 out_features를 원소로 가지고 있다. out_feat_list의 길이는 num_layers와 항상 동일해야만 한다. (assert문 참고)\n",
        "* \\_\\_init\\_\\_ 함수의 parameter 중 act는 activation function을 의미한다. MLP의 모든 layer 뒤에는 항상 해당 activation function이 위치해야 한다. 문자열(string)으로 입력되며 'sigmoid', 'relu', 'tanh'만  입력되도록 한다. (assert문 참고)\n",
        "* input_data 행렬의 column은 1024로 가정한다. (Hint: 이는 MLP의 첫번째 nn.LInear layer의 input_features과 동일하다.)\n",
        "* 입력 및 모델 구조 출력 예시를 참고한다."
      ],
      "metadata": {
        "id": "rQZTbtZqe3ai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomMLP(nn.Module):\n",
        "  def __init__(self, num_layers: int, out_feat_list: List[int], act: str):\n",
        "    assert len(out_feat_list)==num_layers, 'out_feat_list size should be equal to num_layers'\n",
        "    super(CustomMLP, self).__init__()\n",
        "    activation = self.select_act(act)\n",
        "    layers = list()\n",
        "    ######################## TODO ########################\n",
        "    in_feat = 1024\n",
        "    for out_feat in out_feat_list:\n",
        "      layers.append(nn.Linear(in_feat, out_feat))\n",
        "      if act == \"sigmoid\":\n",
        "        layers.append(nn.Sigmoid())\n",
        "      elif act == \"relu\":\n",
        "        layers.append(nn.ReLU())\n",
        "      elif act == \"tanh\":\n",
        "        layers.append(nn.Tanh())\n",
        "      in_feat = out_feat\n",
        "    ######################################################\n",
        "    self.mlp = nn.Sequential(*layers)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = self.mlp(x)\n",
        "    return x\n",
        "\n",
        "  def select_act(self, act: str):\n",
        "    assert act in ['sigmoid', 'relu', 'tanh'], 'activation should be in [sigmoid, relu, tanh]'\n",
        "    if act == 'sigmoid':\n",
        "      return nn.Sigmoid()\n",
        "    elif act == 'relu':\n",
        "      return nn.ReLU()\n",
        "    else:\n",
        "      return nn.Tanh()\n",
        "\n",
        "model = CustomMLP(num_layers=8, out_feat_list=[6,8,3,4,9,10,2,4], act='sigmoid')\n",
        "print(model)\n",
        "'''\n",
        "출력결과\n",
        "CustomMLP(\n",
        "  (mlp): Sequential(\n",
        "    (0): Linear(in_features=1024, out_features=6, bias=True)\n",
        "    (1): Sigmoid()\n",
        "    (2): Linear(in_features=6, out_features=8, bias=True)\n",
        "    (3): Sigmoid()\n",
        "    (4): Linear(in_features=8, out_features=3, bias=True)\n",
        "    (5): Sigmoid()\n",
        "    (6): Linear(in_features=3, out_features=4, bias=True)\n",
        "    (7): Sigmoid()\n",
        "    (8): Linear(in_features=4, out_features=9, bias=True)\n",
        "    (9): Sigmoid()\n",
        "    (10): Linear(in_features=9, out_features=10, bias=True)\n",
        "    (11): Sigmoid()\n",
        "    (12): Linear(in_features=10, out_features=2, bias=True)\n",
        "    (13): Sigmoid()\n",
        "    (14): Linear(in_features=2, out_features=4, bias=True)\n",
        "    (15): Sigmoid()\n",
        "  )\n",
        ")\n",
        "'''\n",
        "\n",
        "model = CustomMLP(num_layers=12, out_feat_list=[5,8,13,6,4,9,9,2,6,3,9,10], act='relu')\n",
        "print(model)\n",
        "'''\n",
        "출력결과\n",
        "CustomMLP(\n",
        "  (mlp): Sequential(\n",
        "    (0): Linear(in_features=1024, out_features=5, bias=True)\n",
        "    (1): ReLU()\n",
        "    (2): Linear(in_features=5, out_features=8, bias=True)\n",
        "    (3): ReLU()\n",
        "    (4): Linear(in_features=8, out_features=13, bias=True)\n",
        "    (5): ReLU()\n",
        "    (6): Linear(in_features=13, out_features=6, bias=True)\n",
        "    (7): ReLU()\n",
        "    (8): Linear(in_features=6, out_features=4, bias=True)\n",
        "    (9): ReLU()\n",
        "    (10): Linear(in_features=4, out_features=9, bias=True)\n",
        "    (11): ReLU()\n",
        "    (12): Linear(in_features=9, out_features=9, bias=True)\n",
        "    (13): ReLU()\n",
        "    (14): Linear(in_features=9, out_features=2, bias=True)\n",
        "    (15): ReLU()\n",
        "    (16): Linear(in_features=2, out_features=6, bias=True)\n",
        "    (17): ReLU()\n",
        "    (18): Linear(in_features=6, out_features=3, bias=True)\n",
        "    (19): ReLU()\n",
        "    (20): Linear(in_features=3, out_features=9, bias=True)\n",
        "    (21): ReLU()\n",
        "    (22): Linear(in_features=9, out_features=10, bias=True)\n",
        "    (23): ReLU()\n",
        "  )\n",
        ")\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 938
        },
        "id": "r-0TP5iye3rR",
        "outputId": "4e76410d-1be0-439b-afe2-02f29845c3eb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CustomMLP(\n",
            "  (mlp): Sequential(\n",
            "    (0): Linear(in_features=1024, out_features=6, bias=True)\n",
            "    (1): Sigmoid()\n",
            "    (2): Linear(in_features=6, out_features=8, bias=True)\n",
            "    (3): Sigmoid()\n",
            "    (4): Linear(in_features=8, out_features=3, bias=True)\n",
            "    (5): Sigmoid()\n",
            "    (6): Linear(in_features=3, out_features=4, bias=True)\n",
            "    (7): Sigmoid()\n",
            "    (8): Linear(in_features=4, out_features=9, bias=True)\n",
            "    (9): Sigmoid()\n",
            "    (10): Linear(in_features=9, out_features=10, bias=True)\n",
            "    (11): Sigmoid()\n",
            "    (12): Linear(in_features=10, out_features=2, bias=True)\n",
            "    (13): Sigmoid()\n",
            "    (14): Linear(in_features=2, out_features=4, bias=True)\n",
            "    (15): Sigmoid()\n",
            "  )\n",
            ")\n",
            "CustomMLP(\n",
            "  (mlp): Sequential(\n",
            "    (0): Linear(in_features=1024, out_features=5, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=5, out_features=8, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=8, out_features=13, bias=True)\n",
            "    (5): ReLU()\n",
            "    (6): Linear(in_features=13, out_features=6, bias=True)\n",
            "    (7): ReLU()\n",
            "    (8): Linear(in_features=6, out_features=4, bias=True)\n",
            "    (9): ReLU()\n",
            "    (10): Linear(in_features=4, out_features=9, bias=True)\n",
            "    (11): ReLU()\n",
            "    (12): Linear(in_features=9, out_features=9, bias=True)\n",
            "    (13): ReLU()\n",
            "    (14): Linear(in_features=9, out_features=2, bias=True)\n",
            "    (15): ReLU()\n",
            "    (16): Linear(in_features=2, out_features=6, bias=True)\n",
            "    (17): ReLU()\n",
            "    (18): Linear(in_features=6, out_features=3, bias=True)\n",
            "    (19): ReLU()\n",
            "    (20): Linear(in_features=3, out_features=9, bias=True)\n",
            "    (21): ReLU()\n",
            "    (22): Linear(in_features=9, out_features=10, bias=True)\n",
            "    (23): ReLU()\n",
            "  )\n",
            ")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n출력결과\\nCustomMLP(\\n  (mlp): Sequential(\\n    (0): Linear(in_features=1024, out_features=5, bias=True)\\n    (1): ReLU()\\n    (2): Linear(in_features=5, out_features=8, bias=True)\\n    (3): ReLU()\\n    (4): Linear(in_features=8, out_features=13, bias=True)\\n    (5): ReLU()\\n    (6): Linear(in_features=13, out_features=6, bias=True)\\n    (7): ReLU()\\n    (8): Linear(in_features=6, out_features=4, bias=True)\\n    (9): ReLU()\\n    (10): Linear(in_features=4, out_features=9, bias=True)\\n    (11): ReLU()\\n    (12): Linear(in_features=9, out_features=9, bias=True)\\n    (13): ReLU()\\n    (14): Linear(in_features=9, out_features=2, bias=True)\\n    (15): ReLU()\\n    (16): Linear(in_features=2, out_features=6, bias=True)\\n    (17): ReLU()\\n    (18): Linear(in_features=6, out_features=3, bias=True)\\n    (19): ReLU()\\n    (20): Linear(in_features=3, out_features=9, bias=True)\\n    (21): ReLU()\\n    (22): Linear(in_features=9, out_features=10, bias=True)\\n    (23): ReLU()\\n  )\\n)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "===================================================================================================="
      ],
      "metadata": {
        "id": "Le8rbkmcP0du"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "===================================================================================================="
      ],
      "metadata": {
        "id": "JNwQ0rAmP0Uc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section II. 이미지 분류 예측 모델 학습"
      ],
      "metadata": {
        "id": "qEM9XM-c7yL5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CIFAR10 데이터\n",
        "### train: 50,000장\n",
        "### test: 10,000장\n",
        "### label: 10개 (airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck)"
      ],
      "metadata": {
        "id": "cKYBqeAHOcPb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 구글 드라이브 사용 희망 시 아래 코드 주석 해제하고 실행\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive',force_remount=True)"
      ],
      "metadata": {
        "id": "EPGIRI5kPMeE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "911ff4b3-5192-43fd-f4e4-5e63224006be"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets\n",
        "from torchvision.transforms import functional as TF\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "dZg9cAfWPGWG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 코랩 임시 저장소 또는 구글 드라이브에 데이터 저장\n",
        "## 둘 중 원하는 방법 선택하여 실행\n",
        "#### 참고: 데이터 사이즈 약 350MB"
      ],
      "metadata": {
        "id": "ygQxBQkLnNCt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 임시 저장소에 저장 / 코랩 런타임 끊길 경우 초기화\n",
        "# train_data = datasets.CIFAR10(root = './data', train = True, download = True)\n",
        "# test_data = datasets.CIFAR10(root = './data', train = False, download = True)\n",
        "\n",
        "# 구글 드라이브에 저장 / 코랩 런타임 끊기더라도 초기화 되지 않음\n",
        "trainset = datasets.CIFAR10(root = '/content/drive/MyDrive/data', train = True, download = True)\n",
        "testset = datasets.CIFAR10(root = '/content/drive/MyDrive/data', train = False, download = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100,
          "referenced_widgets": [
            "b9f4f2b191a44c57b6ffcbd5531a026b",
            "14bea2ded3d94d6384b90ff94f873858",
            "5767f3a3d1134c9bb54598efe96c27a5",
            "cd1b31b6334242cd91d77449a849f63e",
            "c23649b02ea645dab41507d82aa52076",
            "56822029b6ae49a281b416da13e809b8",
            "d9a19f56e2d14e009b8964ef83b3f81e",
            "9aad1595eddf4db8bba99ff7b1d3a3a4",
            "25152b8e617b4dd99ba466afc3bf2fde",
            "b9538599fe6c4837a60e4f1b3b0a241e",
            "3ba8e98ccb0246f9ad0075ce59f2e26a"
          ]
        },
        "id": "L3pJ-j4Slj5O",
        "outputId": "6851c1da-f7a9-46a4-972f-e9974dbd825f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /content/drive/MyDrive/data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b9f4f2b191a44c57b6ffcbd5531a026b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/drive/MyDrive/data/cifar-10-python.tar.gz to /content/drive/MyDrive/data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 상세정보 확인"
      ],
      "metadata": {
        "id": "mIno48Ofnp6P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data 사이즈 확인\n",
        "print(len(trainset), len(testset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xi1mezKinpYU",
        "outputId": "dac9d33d-3025-414b-a0ba-19c4cd594d30"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50000 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train data 이미지 및 레이블 확인\n",
        "image, label = trainset[0]\n",
        "plt.imshow(image)\n",
        "plt.show()\n",
        "\n",
        "print(f'image type: {type(image)}')\n",
        "print(f'label: {label}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "s_MqoHXymhNC",
        "outputId": "1eb12276-fc37-4ab6-fbf8-42976eaf39e0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAfMklEQVR4nO2da2yc53Xn/2dunOGdFC+SKNmy5UvtNLbiqIbXyXaTBi3coKgTYJFNPgT+EFRF0QAN0P1gZIFNFtgPyWKTIB8WWSgbt+4im8vm0hiFsW1qpDDaFK7l2PG9tizLkSiKokRS5HCGcz37YcZb2fv8H9IiOVTy/H+AoOF7+LzvmWfe877zPn+ec8zdIYT41Sez2w4IIXqDgl2IRFCwC5EICnYhEkHBLkQiKNiFSITcVgab2X0AvgogC+B/uPsXYr+fz+e9r1gM2lqtFh2XQVgezBo/ViHHr2P5iC2XzVKbWfiAZpFrZsTHZpO/55ggmo35SKTUtrf5sdr8aJaJvIEI7Xb4vcV8j+4v4r9FJpnZMhE/shn+ebJzAADaERnbYycCGxPdX5jF5VWUK+vBg111sJtZFsB/A/DbAM4CeNLMHnH3F9mYvmIRR+56b9C2vLxIj9WXCX/Q4wU+Gdft6ae2yfEBapsYHaS2QjYf3J7rK9ExyPIpXlxaprZ6k7+3sdERasu0GsHttVqNjllfX6e2Yil8cQaAFvjFqlItB7ePjA7TMXC+v3qtTm1ZhD8XgF9chgb55zwwwM+PfJ7PRzXio8duCJnwORJ7z00PXzy++I3v88NwDzbkbgAn3f2Uu9cBfBvA/VvYnxBiB9lKsM8AOHPFz2e724QQ1yBbembfDGZ2DMAxAOjr69vpwwkhCFu5s88COHjFzwe6296Cux9396PufjSX589WQoidZSvB/iSAm83sBjMrAPg4gEe2xy0hxHZz1V/j3b1pZp8G8NfoSG8PufsLsTHr6+t44cXwryxfvEjHjZMFUNvDV0YnWkPUZqUpaltrc1Wg3AqvkLsV6JjKOl9RrVT5CnmjxaWmixHNsZgL+9hs8v1lyWowEH/0qqyvUVuzHX7ftr6HjslEVLlGRE0o5fh5UCYr2outJh3T389X4y3Dv50aUWsAABE5r7IeVlCajfB2AMjmwp9LY71Kx2zpmd3dHwXw6Fb2IYToDfoLOiESQcEuRCIo2IVIBAW7EImgYBciEXb8L+iuJAOglCOyUeSP664nEtuhaZ4QMjU5Tm2lmLQSyWqq1sIJI+sNLgt5ZH+FUiSBJpII421+vJHxcAJQs8H3V8hzPyLJiMgW+IdWq4fnqtHk89Ef2V9ugPtYjIxrWlgezESy6JqRDLVYpuXgAE++Kq9VqK3RDEtssYTD1ZXLwe3taPaoECIJFOxCJIKCXYhEULALkQgKdiESoaer8WaOooUTEIaGuCu3zIwFt+8p8cyJfJuXWiov8uSUVptf/6qVsO8ZngeD4UiZq1xkFXn58iofF/nUxofCK8KrKzxppR5JaKmSJA0gXldtkJR2atR5okamxd9YPpKQ0yKluAAgR5bPazU+ppDnH2imzRNoauUlagNJogKAPnIaN9tcMbi8FlZkWpF6grqzC5EICnYhEkHBLkQiKNiFSAQFuxCJoGAXIhF6Kr3lzDDWFz5kKSKtjJAkiMlhXvOrRdoPAYj0MQGyuUghNFJHrNaOSD8RnSwXScZo1bhE5Vl+jb5wIdxlptXg73q1wpM0Ki0uUw6WIt1daqT9E/h7zhiXjbJ9kU4sa1xm7c+HfcxFWiutR+oGVhtcemtHmnYtl7mPy5Xw+VMmUi8ArDfC50A9UmtQd3YhEkHBLkQiKNiFSAQFuxCJoGAXIhEU7EIkwpakNzM7DWAVHTWr6e5HowfLGiZHwxLKUJ5LXsVi2JbJcqmjFKnv1mhyGaodyeTqtKH//6lH6sW16lyWa3skoywieXmOZ2Wt1sMZbK0Wn99KpNVUM2JbXeP+zy6G/chn+P6Gy3zuG+d5e7DqZS4dXjdxU3D71NQBOsaGwvXdAKC2dInaymWePXh5lUtvFy+HZdbTZ7gfrWw4dGt1Ltdth87+QXfnn4QQ4ppAX+OFSIStBrsD+Bsze8rMjm2HQ0KInWGrX+Pf7+6zZjYF4Mdm9rK7P37lL3QvAscAoBh5LhdC7CxburO7+2z3/wsAfgjg7sDvHHf3o+5+tJDTU4MQu8VVR5+ZDZjZ0JuvAfwOgOe3yzEhxPayla/x0wB+2G2XlAPwv9z9/8QG5HNZ7J8MFyIcLnDJYLA/LDVZRLpCJAPJItlmtSqXcTJEltszxNtQDQzwbK2Vy1zEGBnmGWWrkSKQb8yG91mu8UeoAp8OzPRHsvbyPDPv9KVw9l3NI0VCI1lvI8ND1Hbv7VzxXZkLy6xeiRxrgmdT1ip8Psplfu/sy/N9Htwbfm9TU9N0zPxKWMq79Mp5Ouaqg93dTwG482rHCyF6ix6ihUgEBbsQiaBgFyIRFOxCJIKCXYhE6G3ByaxhfCicjZarh6UaAOjLh93s7wv3NQOAWpXLU41Iv67R0XBfOQBwUqSw3uLXzEYjUgxxkPeBO7cQ7uUFAK+9wbOhFlbD7y1SuxDXR3rmfeRfH6G2A/u4/9976lRw+z+e5NJQs80z/XIZLpWtLi9QW6UcnsehIS6FocWz74pFPq5AsjMBoN/4uGYr/OFcd3A/HTO0GO4F+OzrfC50ZxciERTsQiSCgl2IRFCwC5EICnYhEqG3q/G5HKbG9wRt1UW+ap2xsJtl0jYHAKqxWlwWqccWaZPErozVBl9FHh3jCS31Fl9hPnX2HLUtrnAfWX26bKRl1HCR728qF171BYDiIlcMbh7eG9w+N879mF++QG21Cp/jp195hdoypB1SYyDSumqEJ6Agw0NmZISrQ0PtSLspUqfQ6yt0zCGSUNaX5/OrO7sQiaBgFyIRFOxCJIKCXYhEULALkQgKdiESocfSWx5jE5NB29ggb9eUyYSTCJZXluiYxlqZ768Va//EC7I5ScgZHOR15hrgtpdOcclorcZbCRWLfdxWCPtYGuCy0FiWy5RPnZyntmadnz61kbD0NjnG58PA5bBGk0uzlTqvhbdGas3Vm/w9W0RKjXQHQz4TaR2WidTey4XnsVnj0qYT2ZbkagHQnV2IZFCwC5EICnYhEkHBLkQiKNiFSAQFuxCJsKH0ZmYPAfg9ABfc/de728YBfAfAIQCnAXzM3bkO9i97A4iMZpH2OIy+SD2wfoSzggAgF7nGZTKRenJElusr8fZPF8/zrLHKRT5lN45ziarGVSgUicR26+EZOiYT2WEzy+d4JSJ95rLhOnlDBf657Bk7TG2Hb76O2l7/xZPU9vIrs8HthVxE1nIu2zabPGQyJOMQAPIFPo/tdvi8akd0PrPweRpRBjd1Z/9zAPe9bduDAB5z95sBPNb9WQhxDbNhsHf7rS++bfP9AB7uvn4YwEe22S8hxDZztc/s0+4+1319Hp2OrkKIa5gtL9B5p5g6/SM9MztmZifM7MRqJfKwKYTYUa422OfNbB8AdP+n9YTc/bi7H3X3o0P9fNFJCLGzXG2wPwLgge7rBwD8aHvcEULsFJuR3r4F4AMAJszsLIDPAfgCgO+a2acAvAHgY5s5WNsd1fVwcT1r8MwlIJyhtLbGC/LVG/w61szwbxjlCpfKVoht5iCfRm/y/V0/wYWSw/u5VFNZ5+NmbrkzuL3g/BFq6TIv3FkaDRcIBQBc4plcB/fuC25fXuPZfDf+2s3UNjzGs/aGx26jtqWF8PwvXeYttPIReTDjPOOw0Y5kU/JkSrQa4fM7kkRHW5FFkt42DnZ3/wQxfWijsUKIawf9BZ0QiaBgFyIRFOxCJIKCXYhEULALkQg9LTjpcLQsLE94ixcAZDJDqciLVA4Ocanm3AKX+V4/u0BtuXzYj8I878u2Ps/3d/MUl9c+9AEuQ702+/ZUhX9haCZc0HNiT7gAJABcWOBFJUdHIzJUm/tfIAUWLyyEs9AAIFdcpraF5Tlqm53jWWr5fPg8GB3mWli1ygUsz/H7o0W0snZElstYeJxFMjAjbQL5cd75ECHELyMKdiESQcEuRCIo2IVIBAW7EImgYBciEXoqvWWzGYyODgZtzRyX3srlcMaWN7iccXmVZzW98QsuNZXLXMYpFcPXxrnXefbddJEXIZyZuZ7aRvffQG351UgKFSnCeeDOu/mQ81wOKzW5dNgCz6RbWwvb9vWHpUEAqLf4+7KB8HkDAAcG9lPb0GhYcly9dJ6OuTB/idoaxuXG9TovYokM18oG+sJZmPVqRFIkBSyNyHiA7uxCJIOCXYhEULALkQgKdiESQcEuRCL0dDW+3WpidTm80pmr81ptedLqBrwEGnJZbqyU+Ur92BBP/BgdCK+aVpf4avzUfl7DbeaOf0Ntz5+tU9srJ7nt3n3jwe3Ly3zM9OFw3ToAyKBCbfUaX6kf9fDK+soFvtJdqvNaePvGw+8LAJZbvC5c/o6x4PZqJLHmHx59hNrOnuHvORtp8RRrzMTybhqxNmWN8FyxpDFAd3YhkkHBLkQiKNiFSAQFuxCJoGAXIhEU7EIkwmbaPz0E4PcAXHD3X+9u+zyAPwDwpg7xWXd/dDMHzBIFohX5o38nskWGtIUCgJZx6W2JKzxYWYnUH6uF5at9I1yu+40PfpDaDtx6D7X94M8eora9kaSQbD1cX2/21Gt8fzfeTm3FPTdR24BzubSyGO71WWqHpTAAqFe5zHdxldtGJ3nS0J69h4Lbq+VhOibDTWgVePJPrAZdo8GlT2uGE7rMeaJXsxkO3a1Kb38O4L7A9q+4+5Huv00FuhBi99gw2N39cQC8nKkQ4peCrTyzf9rMnjWzh8yMfzcTQlwTXG2wfw3AYQBHAMwB+BL7RTM7ZmYnzOxEucKfW4QQO8tVBbu7z7t7y93bAL4OgJZBcffj7n7U3Y8O9vOqLUKIneWqgt3M9l3x40cBPL897gghdorNSG/fAvABABNmdhbA5wB8wMyOAHAApwH84WYOZgCMKAMtksUD8DY4kU488Gpkf5ESbuN7eNuovf1hqe+uo7fQMbfdy+W1pQtcbuxr8sy8Gw8coLY2eXN7p3jtt+Y6lzArkWy5epOPa1TDp1YLXDZ8bfYstT33/Alqu/ce7uOeveGsw5XVsDQIAKRjFABg4hCXWduxdk31iIxGJN3LC7wdVm017GSbZBsCmwh2d/9EYPM3NhonhLi20F/QCZEICnYhEkHBLkQiKNiFSAQFuxCJ0NOCk+5Am2T4VGtcMiiQLK9cjhf4y2a4HHPTXv7XvcUSv/4duv5gcPud7+eZbftuvYPanvnHP6O26w5yH/e+693UVpg8HNye6x+hYyrrXAKsrvDMtvlzZ6htaT4so7UaPHutNBQu6AkAExP8sz5z7mlqm943E9zerESyLKu8jZOtLVFby8MZhwDgTHMGUOoLv7fCXv6eV/pIJmgkonVnFyIRFOxCJIKCXYhEULALkQgKdiESQcEuRCL0VHozM+Sz4UMuRQoKttbDMkOpv0THZDNc6piKZLadmeOZRofvCpXiAw68O7y9A5fQGqtr1DYyxKWyyVuOUNtaLtwT7YWnn6RjalXux8oKn4+Ls7+gtmwrLH0Wi/yUm7khLJMBwB238MKXzSzPRMtnR8PbCzwrMrfOi0pW3pilNiYrA0Azclstk76E/Xv4+5omPQTz+Uh/OO6CEOJXCQW7EImgYBciERTsQiSCgl2IROhtIky7jVo1vNLZ38ddsWJ4tTKf4TXQvMVtpUHeGur3/93vU9u9v/uh4PbhiWk6Zv7US9SWjfi/vMpr0C2c/mdqO7caXhH+u7/8SzpmsMQTLtZrPGFk7zRXDIaHwivJr5/lyTP1yHyM7z9Ebbe8+73UhlZfcPPiMq93VyHqDwAsVbmP5vwcXq/yRK8yadnkZa4K3BYWGdDmIpTu7EKkgoJdiERQsAuRCAp2IRJBwS5EIijYhUiEzbR/OgjgLwBMo9Pu6bi7f9XMxgF8B8AhdFpAfczdeYEuAA5H20ltuDZPIrBmWLZoeqTFU6TmV7FvmNqOvJfLOH35sET14jO8BtrSudeorVbj0srq0iK1nTn5IrWVPZwclG/xYw3muBQ5XOTJGJNjXHqbmz8f3N6MtPmqrHKZ78zrPOkGeIFayuVwDb1ijp8fzb4parvU5OdOqcRr6PUP8aStUi4sD65WVuiYZjssAUaUt03d2ZsA/tTdbwdwD4A/NrPbATwI4DF3vxnAY92fhRDXKBsGu7vPufvPuq9XAbwEYAbA/QAe7v7awwA+slNOCiG2zjt6ZjezQwDeA+AJANPuPtc1nUfna74Q4hpl08FuZoMAvg/gM+7+locJd3eQxwUzO2ZmJ8zsxFqV13IXQuwsmwp2M8ujE+jfdPcfdDfPm9m+rn0fgGDDa3c/7u5H3f3oQKmwHT4LIa6CDYPdzAydfuwvufuXrzA9AuCB7usHAPxo+90TQmwXm8l6ex+ATwJ4zsye6W77LIAvAPiumX0KwBsAPrbxrhxAWEZrN/lX/Fw+XDOuFan5VQfPTpoe4XXh/vqRv6K28emwxDO1L9wWCgDqFZ69ls+HJRcAGBzgEk8uw6WyASIP7p0K1ywDgOoqV0xLWe7jpYWL1Naohz+boSKXoOplLr29+vQJapt7+RVqqzVJS6Y8n8NWbH4PcCkSA/wczvRx6bNIZLQx8Lm67V03BLeXiqfomA2D3d3/HgDL+QvnfAohrjn0F3RCJIKCXYhEULALkQgKdiESQcEuRCL0tOAk3NBuhxf2C5HMq2KOFOvL8MKAHmkJ1K7zzKuLF8PZWgBQXgjbSg2endQGf1/jY1wOG90/SW3NVo3aZs+FffRIPlQmw0+DepNLmFnjhSoHimG5lCQwdvYXM0ayGFt1Lm9myPm2UuFyY72PyHUAhvbzuV8r8VZZq20uy62vhe+5e4ZvpGMmiJSay/PPUnd2IRJBwS5EIijYhUgEBbsQiaBgFyIRFOxCJEJvpTcYMhbOoir28QwfJxlsA6WwvAMAA0MT1FZp8AykPUM85z5H/Khfnqdj2hm+v0qeS03T0+GsJgBo17mMc+sdB4Lbf/qTx+iYuleoLW9c3qyW+bjhoXDWXiHHT7msRfqhrfPP7PU5LqMtL4c/s5qt0TGTt/B74MxoJGvP+We9dJHPVWE9LGEOzEQyFSvhrMJ2RL3UnV2IRFCwC5EICnYhEkHBLkQiKNiFSISersZnDCjkwteXSo0nGGRJC6J2pD5apcGTGbJ5nlTRV+Crrfl82I9CP2+DNDLME3LOL/BV/MpMeFUdAKYO3kRtsxfCdeHe9Rvvo2PKC+eo7dQrvLXSWpknfuSy4fkfGeG19YzUJwSAuVnu4y/eiCTC9IXnf3iaKzmT4xEfI6qALfLPemyJh9rM1Hhw+4FRfg6cfDGc8FSr8iQv3dmFSAQFuxCJoGAXIhEU7EIkgoJdiERQsAuRCBtKb2Z2EMBfoNOS2QEcd/evmtnnAfwBgIXur37W3R+NHixnmJ4MX18aly7RcdVWWJJZ47kM8AxvDZWLJGMMD/PkgwJprVRd4zXoSpGaYKhz24mf/pTabryVS3Znz4YlmUykXl9/H68ll43Im6USl5rWymHprVrlkmgz0gJssMT9uPc9t1BbkSTkNLO8tl6rwZNWqme49JZZLVLbVP8Qtb3nlneFx4zyLuhPzb0e3N5s8Pe1GZ29CeBP3f1nZjYE4Ckz+3HX9hV3/6+b2IcQYpfZTK+3OQBz3derZvYSgJmddkwIsb28o2d2MzsE4D0Anuhu+rSZPWtmD5kZb40qhNh1Nh3sZjYI4PsAPuPuKwC+BuAwgCPo3Pm/RMYdM7MTZnZipcKfyYQQO8umgt3M8ugE+jfd/QcA4O7z7t5y9zaArwO4OzTW3Y+7+1F3Pzrczyt5CCF2lg2D3cwMwDcAvOTuX75i+74rfu2jAJ7ffveEENvFZlbj3wfgkwCeM7Nnuts+C+ATZnYEHTnuNIA/3GhHhYLhuoPhu/uIcdni5JmwFDK/wLPX6i0u1QwO8re9VuEZVK12Obg9G7lmLi5wSXG1zGWS9Qb3I+vcNjQYXjqZP79Ix5xd43JS27lkNz3JZUprh7OvlpZ5vbi+Af6ZjY5w6aqQ5fNfqxMJNsflxrUa31+9HGl51ebjbjq4l9r27w3P45mzXGK9tBCOiWakhdZmVuP/HkDoE49q6kKIawv9BZ0QiaBgFyIRFOxCJIKCXYhEULALkQg9LTiZzRmGx0jmGJESAGBsKhs2DPCigRfneQHL9Uj7pFyBFxtkw9oNnmHXaHE/Lle5DDUQyfJar3CprLoeLjhZj/jYitjcydwDKK9E2j8Nhwt3Dg/z4pzVKt/fxUt8rgYHefadZcL3M2ty2baQ40VH+7hCjEKBz9Whmw5RW7US9uXxx1+kY5595UJ4X+tcztWdXYhEULALkQgKdiESQcEuRCIo2IVIBAW7EInQU+nNzJArhg9ZHOa57uOD4WtSrsplrXyJZ/+sRPpuocWvf6XiVHhInh+rVeP90Ar93I98js9HNsslx5qHfak3uNzokcw24woVvM4lwBYx5SPZZihwuXF5iUtv1TrvbzYyGpZSc0SSA4BMZO4r4NLW/MVValuKZDiuroWzGP/2717mxyIq5Xpd0psQyaNgFyIRFOxCJIKCXYhEULALkQgKdiESoafSW7ttKLOCfdlBOm5wIKzj5EtcFxqIpCeNjHCprLzCe5GVV8IFAMuVSNbbOrcNFXjBxiLpKwcAzRqXHHO58PW7ELms5/t4tpYZH9gfKdyZIaZmi0tDhVKkB98olxsXF7nktUqkyOFxPveVSM+5V0/zAqIvP3eG2qbHeTbl9AHy3jL8PJ0gBTjnV7kMqTu7EImgYBciERTsQiSCgl2IRFCwC5EIG67Gm1kRwOMA+rq//z13/5yZ3QDg2wD2AHgKwCfdPdqmtV4Hzr4RttWW+er50GR4BbdYiiRA8MV9jI/zt11e43XQlpfDtqVLPHFiiS/eItvmq+Bt50pDq8VX+NEO22JXdcvwRJhsjs9VNZI05GTRPU/aQgFAs8JbVLUi9elakeSa5XJ4HOsKBQCLEUXm9En+gS5fWqO2+ho/4N6RcGuo266foWOYi6+eX6FjNnNnrwH4LXe/E532zPeZ2T0AvgjgK+5+E4AlAJ/axL6EELvEhsHuHd7saJjv/nMAvwXge93tDwP4yI54KITYFjbbnz3b7eB6AcCPAbwGYNn9/31ZOwuAf+cQQuw6mwp2d2+5+xEABwDcDeDXNnsAMztmZifM7MTlMi92IITYWd7Rary7LwP4CYB/BWDUzN5cvTkAYJaMOe7uR9396MhgpMK+EGJH2TDYzWzSzEa7r0sAfhvAS+gE/b/t/toDAH60U04KIbbOZhJh9gF42Myy6Fwcvuvuf2VmLwL4tpn9ZwBPA/jGRjtyy6GVnwjaGoWjdFytHU78yDTDrY4AoDjC5aTRSf4NYyzDEzXGK+HEhOVF3i5o+SKX16prfPpbTS7nwfk1ut0M+7he5Y9QhUKk3l2O+7+6zhM1quSRLR9RZ4cy4eQOAGhnuKTUaPB57BsIS5jFPK93N1rgPt6IUWp79528DdWtd9xJbYduuim4/e57uNx49lw5uP0fXuMxsWGwu/uzAN4T2H4Kned3IcQvAfoLOiESQcEuRCIo2IVIBAW7EImgYBciEcwj2VXbfjCzBQBv5r1NAOA6Qe+QH29FfryVXzY/rnf3yZChp8H+lgObnXB3Lq7LD/khP7bVD32NFyIRFOxCJMJuBvvxXTz2lciPtyI/3sqvjB+79swuhOgt+hovRCLsSrCb2X1m9s9mdtLMHtwNH7p+nDaz58zsGTM70cPjPmRmF8zs+Su2jZvZj83s1e7/Y7vkx+fNbLY7J8+Y2Yd74MdBM/uJmb1oZi+Y2Z90t/d0TiJ+9HROzKxoZv9kZj/v+vGfuttvMLMnunHzHTOLpEYGcPee/gOQRaes1Y0ACgB+DuD2XvvR9eU0gIldOO5vArgLwPNXbPsvAB7svn4QwBd3yY/PA/j3PZ6PfQDu6r4eAvAKgNt7PScRP3o6JwAMwGD3dR7AEwDuAfBdAB/vbv/vAP7onex3N+7sdwM46e6nvFN6+tsA7t8FP3YNd38cwNvrJt+PTuFOoEcFPIkfPcfd59z9Z93Xq+gUR5lBj+ck4kdP8Q7bXuR1N4J9BsCV7S53s1ilA/gbM3vKzI7tkg9vMu3uc93X5wFM76IvnzazZ7tf83f8ceJKzOwQOvUTnsAuzsnb/AB6PCc7UeQ19QW697v7XQB+F8Afm9lv7rZDQOfKjs6FaDf4GoDD6PQImAPwpV4d2MwGAXwfwGfc/S2laXo5JwE/ej4nvoUir4zdCPZZAAev+JkWq9xp3H22+/8FAD/E7lbemTezfQDQ/f/Cbjjh7vPdE60N4Ovo0ZyYWR6dAPumu/+gu7nncxLyY7fmpHvsd1zklbEbwf4kgJu7K4sFAB8H8EivnTCzATMbevM1gN8B8Hx81I7yCDqFO4FdLOD5ZnB1+Sh6MCdmZujUMHzJ3b98hamnc8L86PWc7FiR116tML5ttfHD6Kx0vgbgP+ySDzeiowT8HMALvfQDwLfQ+TrYQOfZ61Po9Mx7DMCrAP4WwPgu+fE/ATwH4Fl0gm1fD/x4Pzpf0Z8F8Ez334d7PScRP3o6JwDuQKeI67PoXFj+4xXn7D8BOAngfwPoeyf71V/QCZEIqS/QCZEMCnYhEkHBLkQiKNiFSAQFuxCJoGAXIhEU7EIkgoJdiET4vyrWWZ/xQ9u6AAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image type: <class 'PIL.Image.Image'>\n",
            "label: 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch에서 neural network에 대한 모든 입력은 PyTorch에서 정의한 Tensor라는 자료구조를 사용해야 함\n",
        "### 위 셀에서 image type은 <class 'PIL.Image.Image'>이므로 변형 필요\n",
        "### TF.to_tensor 함수 사용"
      ],
      "metadata": {
        "id": "m14SHtCgoZNK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PIL.Image.Image -> torch.Tensor로 변경\n",
        "image = TF.to_tensor(image)\n",
        "print(f'image type: {type(image)}')\n",
        "print(f'image size: {image.size()}') # 3채널(R,G,B), 32(height,세로), 32(width,가로)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4c3GRYonn0J",
        "outputId": "3191c9d2-8db7-47bf-8e70-d6c0f724702a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image type: <class 'torch.Tensor'>\n",
            "image size: torch.Size([3, 32, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 이미지 데이터에 Multi-Layer Perceptron (MLP) 적용하기 위한 pre-processing"
      ],
      "metadata": {
        "id": "Jz9bFyyU5K3y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (review) nn.Linear의 인풋 데이터는 2차원 행렬 형태를 가져야 한다.\n",
        "### 하지만 CIFAR10과 같은 이미지 데이터의 경우 height, width 외에 channel이라는 차원을 가지고 있다. (즉 3차원 데이터)\n",
        "### 따라서 이러한 형태를 2차원 형태로 변환해주는 flattening 과정이 필요하다. (flatten 메소드 사용)"
      ],
      "metadata": {
        "id": "EmrgzybDQAB7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# flatten, permute\n",
        "image, label = trainset[1214] # train data 1개 load\n",
        "image = TF.to_tensor(image)\n",
        "print(f'image size 확인: {image.size()}')\n",
        "image_flat = image.flatten(start_dim=1, end_dim=2)\n",
        "print(f'flattened image size 확인: {image_flat.size()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTe99wwnP_pC",
        "outputId": "e9bd737e-b393-4e19-8770-ab0704267da0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image size 확인: torch.Size([3, 32, 32])\n",
            "flattened image size 확인: torch.Size([3, 1024])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset 클래스를 새롭게 정의하여 CIFAR10 데이터셋에서 이미지를 불러올 때마다 flatten과 permute를 자동으로 수행하게 한다. 아래와 같이 선언 (코드 수정할 필요 없음)"
      ],
      "metadata": {
        "id": "7u6Gm_2V4nku"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Cifar10Dataset(Dataset):\n",
        "  def __init__(self, dataset, train=True):\n",
        "    super(Cifar10Dataset, self).__init__()\n",
        "    self.dataset = dataset\n",
        "    self.train = train\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.dataset)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    image, label = self.dataset[index]\n",
        "    image = TF.to_tensor(image)\n",
        "    image = image.flatten(start_dim=1, end_dim=2)\n",
        "    # image = image.permute(1,0)\n",
        "    return image, label\n",
        "\n",
        "train_data = Cifar10Dataset(trainset, train=True)\n",
        "test_data = Cifar10Dataset(testset, train=False)\n",
        "\n",
        "image, label = train_data[1234]\n",
        "print(f'image size 확인: {image.size()}')"
      ],
      "metadata": {
        "id": "t7MyKuhO3GXD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04dd858a-3130-45ba-a701-13d036278e51"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image size 확인: torch.Size([3, 1024])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DataLoader\n",
        "\n",
        "### 위처럼 정의된 Dataset에서 데이터를 한 번에 batch_size만큼 불러올 수 있는 기능\n",
        "### 아래와 같이 선언 (코드 수정할 필요 없음)"
      ],
      "metadata": {
        "id": "YAGM9L5S45Ou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DataLoader 사용\n",
        "train_loader = DataLoader(train_data, batch_size=128, shuffle=False, pin_memory=True)\n",
        "test_loader = DataLoader(test_data, batch_size=128, shuffle=False, pin_memory=True)\n",
        "\n",
        "image, label = next(iter(train_loader))\n",
        "print(f'image size 확인: {image.size()}') # [128, 3, 1024] == [batch_size, channel(RGB), height*width]\n",
        "print(f'label size 확인: {label.size()}') # [128] == [batch_size]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROhJ2RSTZIUN",
        "outputId": "39a16ac8-22d0-431c-b6bf-c5bb1d5646d3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image size 확인: torch.Size([128, 3, 1024])\n",
            "label size 확인: torch.Size([128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 본격적인 모델 학습을 위한 model, optimizer, loss function 정의\n",
        "# 학습 후 테스트 진행\n",
        "* 예시 코드 test 정확도 37.15%"
      ],
      "metadata": {
        "id": "NfKFs8Rb7qCc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model, optimizer, loss function 정의 예시\n",
        "torch.random.manual_seed(100)\n",
        "model = CustomMLP(num_layers=5, out_feat_list=[1024,256,64,16,10], act='relu').to(device) # 문제3에서 생성한 CustomMLP 사용\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) # Adam optimizer. lr: learning rate\n",
        "criterion = nn.CrossEntropyLoss() # loss function"
      ],
      "metadata": {
        "id": "Gc37nVwc22hk"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model training 예시 코드\n",
        "from tqdm import tqdm\n",
        "for epoch in range(20):\n",
        "  total_loss = 0.0\n",
        "  total_right = 0\n",
        "  for i, (image, label) in enumerate(tqdm(train_loader)):\n",
        "    image = image.to(device)\n",
        "    label = label.to(device)\n",
        "\n",
        "    # 모델 label 분류 예측\n",
        "    output = model(image)\n",
        "    output = output.max(1)[0]\n",
        "    \n",
        "    # loss 계산\n",
        "    loss = criterion(output, label.long())\n",
        "    total_loss += loss\n",
        "\n",
        "    # 정답을 맞춘 개수 계산\n",
        "    right = (output.max(1)[1] == label).sum()\n",
        "    total_right += right\n",
        "\n",
        "    # Back-Propagation\n",
        "    optimizer.zero_grad() \n",
        "    loss.backward() \n",
        "    optimizer.step()\n",
        "\n",
        "    if i==len(train_loader)-1:\n",
        "      print(f'{epoch+1} average loss: {total_loss/len(train_loader):.6f}')\n",
        "      print(f'{epoch+1} average accuracy: {total_right/len(train_loader.dataset)*100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FX3jQVIT91Ha",
        "outputId": "d2fd95d3-2ca2-4913-9567-1e2f10a07885"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:07<00:00, 52.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 average loss: 2.154141\n",
            "1 average accuracy: 20.92%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:07<00:00, 53.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 average loss: 2.045065\n",
            "2 average accuracy: 27.49%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:07<00:00, 53.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3 average loss: 1.987662\n",
            "3 average accuracy: 29.77%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:07<00:00, 53.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4 average loss: 1.950839\n",
            "4 average accuracy: 31.26%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:08<00:00, 47.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5 average loss: 1.920937\n",
            "5 average accuracy: 32.57%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:07<00:00, 54.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6 average loss: 1.894117\n",
            "6 average accuracy: 33.77%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:07<00:00, 52.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7 average loss: 1.870632\n",
            "7 average accuracy: 34.54%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:07<00:00, 53.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8 average loss: 1.850906\n",
            "8 average accuracy: 35.33%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:07<00:00, 52.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9 average loss: 1.831887\n",
            "9 average accuracy: 36.15%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:07<00:00, 53.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 average loss: 1.815462\n",
            "10 average accuracy: 36.78%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:07<00:00, 53.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11 average loss: 1.797297\n",
            "11 average accuracy: 37.53%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:07<00:00, 53.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12 average loss: 1.778342\n",
            "12 average accuracy: 38.23%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:07<00:00, 54.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13 average loss: 1.762986\n",
            "13 average accuracy: 38.72%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:07<00:00, 54.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14 average loss: 1.745593\n",
            "14 average accuracy: 39.63%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:07<00:00, 53.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15 average loss: 1.730993\n",
            "15 average accuracy: 40.20%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:07<00:00, 53.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16 average loss: 1.713447\n",
            "16 average accuracy: 40.87%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:07<00:00, 54.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17 average loss: 1.699213\n",
            "17 average accuracy: 41.33%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:07<00:00, 54.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18 average loss: 1.684447\n",
            "18 average accuracy: 41.82%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:07<00:00, 53.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19 average loss: 1.670841\n",
            "19 average accuracy: 42.25%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:07<00:00, 53.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20 average loss: 1.653167\n",
            "20 average accuracy: 42.92%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test 예시 코드\n",
        "total_right = 0\n",
        "for i, (image, label) in enumerate(tqdm(test_loader)):\n",
        "  image = image.to(device)\n",
        "  label = label.to(device)\n",
        "\n",
        "  # 모델 label 분류 예측\n",
        "  output = model(image)\n",
        "  output = output.max(1)[0]\n",
        "\n",
        "  # 정답을 맞춘 개수 계산\n",
        "  right = (output.max(1)[1] == label).sum()\n",
        "  total_right += right\n",
        "\n",
        "  if i==len(test_loader)-1:\n",
        "    print(f'TEST average accuracy: {total_right/len(test_loader.dataset)*100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PqWODPLWVJW",
        "outputId": "d8953db7-5f74-4c07-ce60-1c0c44507467"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:01<00:00, 58.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEST average accuracy: 37.15%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 문제4\n",
        "## 아래 조건에 맞게 코드를 작성하고 test 정확도 40% 이상 달성 (5점)\n",
        "\n",
        "### 조건\n",
        "* model은 반드시 문제3에서 생성한 CustomMLP를 사용하도록 한다.\n",
        "* num_layers는 10이 넘지 않아야 한다.\n",
        "* out_feat_list에는 1024를 넘는 수가 없어야 한다.\n",
        "* activation function은 Sigmoid, ReLU, tanh 외에 소개되지 않은 것을 사용해도 상관 없다. 소개되지 않은 activation function을 사용할 경우 select_act 함수를 적절히 수정하도록 한다.\n",
        "* 아래 코드에서 수정해도 되는 것: CustomMLP의 모든 파라미터(단 위 조건에 맞아야 함), SEED, LEARNING_RATE, optimizer\n",
        "* 아래 코드에서 수정하면 안 되는 것: criterion, TRAINING PHASE, TEST PHASE\n",
        "* 성능평가: 테스트 정확도 40% 이상이면 만점, 40% 미만은 1% 구간 별로 1점씩 감점\n",
        "(예: 39.5% -> 1점 감점 38.7% -> 2점 감점)"
      ],
      "metadata": {
        "id": "0J4PjZWyDQtv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "####################################### TODO #######################################\n",
        "SEED = 100 # can be changed\n",
        "LEARNING_RATE = 0.001 # can be changed\n",
        "torch.random.manual_seed(SEED)\n",
        "model = CustomMLP(num_layers=6, out_feat_list=[1024,256,64,32,16,10], act='relu').to(device) # can be changed (but meet conditions above)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE) # can be changed\n",
        "####################################################################################\n",
        "criterion = nn.CrossEntropyLoss() # NEVER CHANGE!!\n",
        "\n",
        "#################################### TRAINING PHASE // NEVER EDIT!! ####################################\n",
        "from tqdm import tqdm\n",
        "for epoch in range(20):\n",
        "  total_loss = 0.0\n",
        "  total_right = 0\n",
        "  for i, (image, label) in enumerate(tqdm(train_loader)):\n",
        "    image = image.to(device)\n",
        "    label = label.to(device)\n",
        "\n",
        "    # 모델 label 분류 예측\n",
        "    output = model(image)\n",
        "    output = output.max(1)[0]\n",
        "    \n",
        "    # loss 계산\n",
        "    loss = criterion(output, label.long())\n",
        "    total_loss += loss\n",
        "\n",
        "    # 정답을 맞춘 개수 계산\n",
        "    right = (output.max(1)[1] == label).sum()\n",
        "    total_right += right\n",
        "\n",
        "    # Back-Propagation\n",
        "    optimizer.zero_grad() \n",
        "    loss.backward() \n",
        "    optimizer.step()\n",
        "\n",
        "    if i==len(train_loader)-1:\n",
        "      print(f'{epoch+1} average loss: {total_loss/len(train_loader):.6f}')\n",
        "      print(f'{epoch+1} average accuracy: {total_right/len(train_loader.dataset)*100:.2f}%')\n",
        "#######################################################################################################\n",
        "\n",
        "###################################### TEST PHASE // NEVER EDIT!! #####################################\n",
        "total_right = 0\n",
        "for i, (image, label) in enumerate(tqdm(test_loader)):\n",
        "  image = image.to(device)\n",
        "  label = label.to(device)\n",
        "\n",
        "  # 모델 label 분류 예측\n",
        "  output = model(image)\n",
        "  output = output.max(1)[0]\n",
        "\n",
        "  # 정답을 맞춘 개수 계산\n",
        "  right = (output.max(1)[1] == label).sum()\n",
        "  total_right += right\n",
        "\n",
        "print()\n",
        "print()\n",
        "print(f'TEST average accuracy: {total_right/len(test_loader.dataset)*100:.2f}%')\n",
        "#######################################################################################################"
      ],
      "metadata": {
        "id": "2rE9cdrwDQR6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0fac60d-0769-4e16-c950-c559e78d6af3"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:07<00:00, 51.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 average loss: 2.167989\n",
            "1 average accuracy: 20.64%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:07<00:00, 52.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 average loss: 1.977285\n",
            "2 average accuracy: 28.75%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:07<00:00, 52.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3 average loss: 1.897600\n",
            "3 average accuracy: 31.70%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:07<00:00, 52.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4 average loss: 1.844737\n",
            "4 average accuracy: 33.77%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:07<00:00, 51.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5 average loss: 1.800086\n",
            "5 average accuracy: 35.31%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:07<00:00, 50.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6 average loss: 1.758770\n",
            "6 average accuracy: 36.80%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:07<00:00, 50.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7 average loss: 1.718643\n",
            "7 average accuracy: 38.52%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:07<00:00, 51.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8 average loss: 1.684823\n",
            "8 average accuracy: 39.85%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:07<00:00, 51.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9 average loss: 1.653479\n",
            "9 average accuracy: 40.91%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:07<00:00, 51.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 average loss: 1.627182\n",
            "10 average accuracy: 41.96%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:07<00:00, 51.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11 average loss: 1.600345\n",
            "11 average accuracy: 42.92%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:07<00:00, 51.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12 average loss: 1.576683\n",
            "12 average accuracy: 43.65%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:07<00:00, 51.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13 average loss: 1.553577\n",
            "13 average accuracy: 44.58%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:07<00:00, 51.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14 average loss: 1.528862\n",
            "14 average accuracy: 45.43%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:07<00:00, 51.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15 average loss: 1.508136\n",
            "15 average accuracy: 46.10%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:07<00:00, 51.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16 average loss: 1.486437\n",
            "16 average accuracy: 47.09%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:08<00:00, 47.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17 average loss: 1.465462\n",
            "17 average accuracy: 47.88%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:08<00:00, 46.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18 average loss: 1.446458\n",
            "18 average accuracy: 48.55%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:07<00:00, 50.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19 average loss: 1.425548\n",
            "19 average accuracy: 49.41%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:07<00:00, 51.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20 average loss: 1.405930\n",
            "20 average accuracy: 50.05%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:01<00:00, 57.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "TEST average accuracy: 42.50%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KldOik_rfV48"
      },
      "execution_count": 23,
      "outputs": []
    }
  ]
}